# ğŸš€ Quick Start Guide

Get started with Q-Learning and DQN in 5 minutes!

## âš¡ Installation (1 minute)

```bash
pip install streamlit numpy pandas plotly torch
```

## ğŸ® Run Applications (1 minute)

### Option 1: Q-Learning (Recommended for beginners)
```bash
streamlit run app.py
```

### Option 2: DQN (Advanced)
```bash
streamlit run app_dqn.py
```

### Option 3: Quick Test
```bash
python test_agents.py
```

## ğŸ¯ First Training (3 minutes)

1. **Open browser** at `http://localhost:8501`

2. **Configure parameters** in sidebar:
   - Grid size: **5** (start small)
   - Episodes: **1000**
   - Learning rate: **0.1** (Q-Learning) or **0.001** (DQN)
   - Epsilon: **0.1**

3. **Click "Start Training"**
   - Watch progress bar
   - Monitor metrics
   - Wait ~30 seconds

4. **Test the agent**
   - Click "Run 1 Episode"
   - Watch step-by-step visualization
   - See the learned path

## ğŸ“Š Understanding Results

### Training Charts

**Rewards Chart**:
- â†—ï¸ Increasing trend = Learning successfully
- â†’ Stable at high value = Converged
- â†˜ï¸ Decreasing = Problem with parameters

**Steps Chart**:
- â†˜ï¸ Decreasing trend = Finding shorter paths
- â†’ Stable = Found optimal path
- â†—ï¸ Increasing = Agent struggling

### Test Results

- **Success**: Agent reaches goal
- **Steps â‰ˆ 2(n-1)**: Near-optimal (straight path is n-1 + n-1)
- **High reward**: Good path efficiency

## ğŸ“ What You'll Learn

### From Q-Learning
- âœ… Reinforcement Learning basics
- âœ… Q-table and Q-values
- âœ… Epsilon-greedy exploration
- âœ… Bellman equation
- âœ… Hyperparameter tuning

### From DQN
- âœ… Deep Reinforcement Learning
- âœ… Neural networks for RL
- âœ… Experience Replay
- âœ… Target Networks
- âœ… Scaling RL to larger problems

## ğŸ”§ Recommended Settings

### First Run (Easy)
```
Grid: 5Ã—5
Episodes: 1000
Learning rate: 0.1 (Q-Learning) / 0.001 (DQN)
Epsilon: 0.1
```

### After Understanding (Challenging)
```
Grid: 10Ã—10
Episodes: 2000
Experiment with different parameters
```

## ğŸ› Quick Troubleshooting

| Problem | Solution |
|---------|----------|
| Import errors | `pip install -r requirements.txt` |
| Port already in use | `streamlit run app.py --server.port 8502` |
| Agent not learning | Increase episodes or reduce epsilon |
| Training too slow | Reduce grid size or episodes |

## ğŸ“š Next Steps

1. âœ… Run Q-Learning successfully
2. âœ… Understand the training charts
3. âœ… Run DQN and compare
4. âœ… Experiment with parameters
5. âœ… Read full [README.md](README.md) for details

## ğŸ’¡ Pro Tips

1. **Start simple**: 5Ã—5 grid, 1000 episodes
2. **Visualize**: Use apps to see agent learn
3. **Compare**: Run both Q-Learning and DQN
4. **Experiment**: Change one parameter at a time
5. **Understand**: Read the code after seeing it work

---

**Ready?** Let's start learning!

```bash
streamlit run app.py
```

For detailed documentation, see [README.md](README.md)